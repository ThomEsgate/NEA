<html>																						
<head>
<script type = "text/javascript">
function metronomeCountIn(bpm) { 																	
	counter = 1;
	function metLoop(){
		document.getElementById("metronomeId").value = (((counter % 4) + 1) + " and a");
		counter++;
		if (counter == 5) { //stop executing
			clearInterval(window.run_metLoop);
		}
	}
	var run_metloop = setInterval(metLoop, (120/bpm) * 500);
	
	beat = document.getElementById("beatAudio");
	//samples_per_beat = (1000/timeBetweenSamples)*(120/bpm)
	//i = 0;
	//console.log("here");
	//var interval = setTimeout( beatIt(), 250 /*samples_per_beat * timeBetweenSamples*/ );
	/*function beatIt() {console.log(i + " and a");
		beat.play;
		console.log("inside");
		sleep(samples_per_beat * timeBetweenSamples); //no don't use sleep
		beat.pause();
		beat.currentTime = 0;
		++i;
		if (i > 4) {clearInterval(interval);}	
		}	*/
}

function getNote(bufferLength, analyser, context, notesArray, timeBetweenSamples, sampleNo, songID, track) {
	songID = parseInt(songID) //string to int
	
	switch(songID) {
		case 01:
		//Astral Alley - 4/4 time sig., 100bpm, in A Minor
			var songArray = [["Astral Alley", 100], ["C", 1], ["A", 6], ["C", 0.5], ["D", 0.5], //bar 1-2 //["C", 1] = Play C note for 1/8th of a 2 bar phrase 1/8 = Crotchet, 0.5/8 = Quaver
												    ["C", 1], ["A", 6], ["C", 0.5], ["D", 0.5], //bar 3-4
													["E", 2], ["D", 2], ["A", 3], ["C", 0.5], ["D", 0.5], //...
													["C", 1], ["A", 6]];
			var bpm = 110;
			break;
		//Lost Woods - 4/4, 130 bpm, in F
		case 02:
			var songArray =[["Lost Woods", "130"],  ["F", 0.5], ["A", 0.5], ["B", 1], ["F", 0.5], ["A", 0.5], ["B", 1], 
													["F", 0.5], ["A", 0.5], ["B", 0.5], ["E", 0.5], ["D", 1], ["B", 0.5], ["C", 0.5],
													["B", 0.5], ["G", 0.5], ["E", 2.5], ["D", 0.5],											
													["E", 0.5], ["G", 0.5], ["E", 3]];
			var bpm = 130;
			break;
		case 03:
			var songArray =[["Latest Trick", "120"] ,["A", 0.5], ["C#", 0.5], ["D#", 0.5], ["E", 0.5], ["C#", 0.5], ["D#", 0.5], ["C#", 0.5], [undefined, 0.5],
													 ["C#", 0.5], ["D#", 0.5],["E", 0.5], ["F#", 1], ["E", 0.5], ["D#", 1], ["C#", 1], 
													 ["B", 1], ["C#", 0.5], ["F#", 0.5], ["E", 1]];
			var bpm = 120;
			console.log("Trick");
			break
		}
		
		var recording = true;
		var silenceTime = 1;
		var currentNote = 1;
		var noteSampleNo = 1;
		var noteSampleIncorrect = 0		
		
		if ((songID == 01) || (songID == 02) || (songID == 03)) {
			var playingSong = true;
			showSong(songId, currentNote); //shows first note
		}
		function repeatRecord() {
			function findFreqFromDataArray(dataArray){
				//goes through entire dataArray of dB values and finds the loudest one (the actual frequency being played, ignoring background noise)
				var highestdB = 0;
				var highesti = 0;
				for(var i = 0; i < analyser.frequencyBinCount; i++) { //for the length of
					if (highestdB < dataArray[i]) {
						highestdB = dataArray[i];
						highesti = i;
					}
				}
				//find frequency by finding the loudest played frequency
				var freq = (context.sampleRate / analyser.fftSize) * highesti
				return freq;
			}
			//create a new array and use the analyser to fill it with byte frequency data   // start and stop buttoons
			var dataArray = new Uint8Array(bufferLength);
			// array to store Frequency values	
			analyser.getByteFrequencyData(dataArray); //stores the frequencies of one place in time into an array
			
			
			var freq = findFreqFromDataArray(dataArray);
			//convert frequency to a note on a keyboard
			var notePosOnKeyboard = Math.round(12 * (Math.log(freq / 440)/Math.log(2)) + 69); //A is 69th key on a keyboard
			var note = notesArray[notePosOnKeyboard % 12]; // % is modulus
			var octaveNo = Math.floor(notePosOnKeyboard / 12);
			
			//PLAYING ALONG* - Astral Alley: 100 bpm - 1 sample per 50 milliseconds = 20 samples/second = 24 samples per beat
			++sampleNo; // a sample has been taken
			var samples_per_beat = (1000/timeBetweenSamples)*(120/bpm) * 0.5;																			//<=== Dodgy???
			var beatNo = Math.floor(sampleNo/samples_per_beat) + 1;
			
			if (playingSong) {
				if (sampleNo == 1) { console.log(songArray[0][0]); //song name
									console.log(songArray[0][1]); //bpm
									metronomeCountIn(bpm);}
								
				//SEEING IF THE NOTE FITS THE SONG
				samples_for_note = (samples_per_beat * songArray[currentNote][1]); //e.g. total samples for a 0.5 beat note is samples per beat * 0
				if (noteSampleNo < samples_for_note) { //if still sampling one note
					++noteSampleNo
					if (note !== songArray[currentNote][0]){ //wrong note
						++noteSampleIncorrect;
					} 
				}
				else{// finished sampling for the note
					function PlayedCorrectly() {
						if (noteSampleIncorrect/noteSampleNo > 0.25 && songArray[currentNote][0] != "silence") {return false;}// if more than 25% incorrect, keep waiting for user to play correct note
						else if (note = "silence" && songArray[currentNote][0] == "silence") {
								return true;
							}
							else {return true;} 

						if ((noteSampleIncorrect/noteSampleNo) > 0.25) {return false;}// if more than 25% incorrect, keep waiting for user to play correct note
						else {return true;} 

						if ((noteSampleIncorrect/noteSampleNo) > 0.25) {return false;}// if more than 25% incorrect, keep waiting for user to play correct note
						else {return true;} 

					}
					if (PlayedCorrectly()) {
						if (songArray.length <= currentNote + 1) { //if reached the end of the song
							console.log("End of song");
							track.stop(); //stops recording	
							clearInterval(run_repeatRecord);
						}
						else {
							console.log(songArray[currentNote][0] + " done! Now play " + songArray[currentNote + 1][0]);
							++currentNote; //next note in songArray	
							showSong(songId, currentNote, songArray[currentNote][0], freq);//show next note to play
						}	
					}
					else {
						console.log("Wrong! Play a " + songArray[currentNote][0])
					}
					noteSampleNo = 0;
					noteSampleIncorrect = 0
				}	
			}
			if (note == undefined) { //cannot approximate note if getByteFrequencyData calculates nothing
				console.log("Undefined note (too quiet?)");
				note = "silence";
				++silenceTime;}
			else {
				silenceTime = 0;
				if (!(playingSong)) {console.log(note.concat(octaveNo)); notesource = "../static/images/" + note + "q.png";}
				document.getElementById("noteId").innerHTML = note; // .innerHTML allows js code to manipulate website being displayed
			}
				if (silenceTime > 99) {track.stop(); //stops recording	
					clearInterval(run_repeatRecord)}; //stops recording after 100 samples of hearing nothing
				document.getElementById("noteId").value = note;
		}	
		var run_repeatRecord= setInterval(repeatRecord, timeBetweenSamples);
		return
} 
   
function Initialise(songID) {
if (navigator.mediaDevices) {
	
	function noUserMedia(){
		console.warn('getUserMedia is NOT supported :(');
		document.getElementById("noteId").innerHTML = 'GetUserMedia not supported :(';
	}			
	
    //getUserMedia takes 3 arguments
    //1. constraints 
    navigator.getUserMedia ({audio: true}, //only uses audio can 
     
    //2. successCallback
    function(stream){
		console.log('getUserMedia is supported');
		
		//checking the transpose - which instrument is played
		if (modeId == 'C') { 
			var notesArray = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]; //C instrument
		} else if (modeId == 'Eb') {
			var notesArray = ["A", "A#", "B", "C", "C#", "D", "D#", "E", "F", "F#", "G", "G#"]; //Eb instrument
		} else {
			console.log("Mode error - unregocnised mode: '" + modeId + "'");
		}
		
		var context = new AudioContext(); // controls creation of audio nodes and contains execution of audio processing
		var source = context.createMediaStreamSource(stream); // sets source of data to be input from microphone
		var analyser = context.createAnalyser(); //analyser can be used to find the frequency of a buffer
		var track = stream.getTracks()[0]; //gets the single audio track as a variable to stop recording
		
		analyser.minDecibels = -60; //lower = more sound picked up, more likely for false readings
		//analyser.maxDecibels = -10;
		//analyser.smoothingTimeConstant = 0.8;
		context.sampleRate = 48000
      
		source.connect(analyser);
		//source.connect(context.destination);	//allows for playback of microphone data through speakers
      
		analyser.fftSize = 16384 //fast fourier transform size - 16384 is best
      
		var bufferLength = analyser.frequencyBinCount;
		
		//Astral Alley: 100 bpm - 1 sample per 50 milliseconds = 20 samples/second = 24 samples per beat
		var timeBetweenSamples = 50; // in milliseconds
		var sampleNo = 0;
											
		//getNote repeats while recording, and will exit the function when the user wants recording to stop
		getNote(bufferLength, analyser, context, notesArray, timeBetweenSamples, sampleNo, songID, track);
		
		//var run_getNotesetInterval = ( function() {getNote(bufferLength, analyser, context, notesArray, timeBetweenSamples)}, 250 )	//STREAM ISN'T THERE NOTHING ON PLAYBACK WHY DOESN'T THIS WORK :(
		console.log("Initialisation Complete");
		return																					
	
    },//3. errorCallback - 
    
    function(err){noUserMedia()});
	return
  };//end of getting user media
  
  console.log("navigator.mediaDevices error");
};

function noteLengthFromNote (noteLengthNum){
	switch(noteLengthNum) {
		//console.log(noteLengthNum);
		case 1 : noteLength = "q"; return noteLength; break;
		case 0.5 : noteLength = "8"; return noteLength; break;
		default : return "q";
	}
}

function showSong(songId, noteInSong, note, freq) {
	switch(songId) {
		case "01":
		//Astral Alley - 4/4 time sig., 100bpm, in A Minor
			var songArray = [["Astral Alley", 100], ["C", 1], ["A", 6], ["C", 0.5], ["D", 0.5], //bar 1-2 //["C", 1] = Play C note for 1/8th of a 2 bar phrase 1/8 = Crotchet, 0.5/8 = Quaver
												    ["C", 1], ["A", 6], ["C", 0.5], ["D", 0.5], //bar 3-4
													["E", 2], ["D", 2], ["A", 3], ["C", 0.5], ["D", 0.5], //...
													["C", 1], ["A", 6]];
			var bpm = 110;
			break;
		//Lost Woods - 4/4, 130 bpm, in F
		case "02":
			var songArray =[["Lost Woods", "130"],  ["F", 0.5], ["A", 0.5], ["B", 1], ["F", 0.5], ["A", 0.5], ["B", 1], 
													["F", 0.5], ["A", 0.5], ["B", 0.5], ["E", 0.5], ["D", 1], ["B", 0.5], ["C", 0.5],
													["B", 0.5], ["G", 0.5], ["E", 2.5], ["D", 0.5],											
													["E", 0.5], ["G", 0.5], ["E", 3]];
			var bpm = 130;
			break;
			
		case "03":
			var songArray =[["Latest Trick", "120"] ,["A", 0.5], ["C#", 0.5], ["D#", 0.5], ["E", 0.5], ["C#", 0.5], ["D#", 0.5], ["C#", 0.5], [undefined, 0.5],
													 ["C#", 0.5], ["D#", 0.5],["E", 0.5], ["F#", 1], ["E", 0.5], ["D#", 1], ["C#", 1], 
													 ["B", 1], ["C#", 0.5], ["F#", 0.5], ["E", 1]];
			var bpm = 120;
			break;
		}
		var noteLength = "";
		var orientation = "";
		noteLength = noteLengthFromNote(songArray[noteInSong][1]);
		
		//if (freq > 500) {var orientation = "flipped";} //note is high enough that the notation changes and the note appears upside down to make space for it    //THIS FLIPS THE NOTE IF THE LAST NOTE THE USER PLAYED IS A HIGH NOTE NOT THE NEW NOTE TO DISPLAY
		
		function getHeight(songArray, noteInSong){
			switch(songArray[noteInSong][0]) {
				case "A#" : var pixelTranslate = 0;  break;
				case "A"  : var pixelTranslate = 0;  break;
				case "G#" : var pixelTranslate = 7;  break;
				case "G"  : var pixelTranslate = 7;  break;
				case "F#" : var pixelTranslate = 14; break;
				case "F"  : var pixelTranslate = 14; break;
				case "E"  : var pixelTranslate = 21; break;
				case "D#" : var pixelTranslate = 28; break;
				case "D"  : var pixelTranslate = 28; break;
				case "C#" : var pixelTranslate = -14;break;
				case "C"  : var pixelTranslate = -14;break;
				case "B"  : var pixelTranslate = -7; break;
				case undefined :var pixelTranslate = 0; console.log("silence");  break;
				default   : console.log("NoteError"); console.log(songArray[noteInSong][0]); break;
				}
			return pixelTranslate;
		}	
		pixelTranslate = getHeight(songArray, noteInSong);
		
		function isSharp(note){
			if (["B#", 'C#', 'D#', "F#", "G#", "A#"].includes(note)) {var sharp = true}
			else{var sharp = false};
			return sharp;
		}
		sharp = isSharp(note)
		if (songArray[noteInSong][0] == undefined){
			console.log("wait for silence");
		}
		else {
			if (sharp) {
				showImage("../static/images/" + noteLength + "sharp" +orientation +".png", note + noteLength + orientation, pixelTranslate);
			}
			else {
				showImage("../static/images/" + noteLength + orientation +".png", note + noteLength + orientation, pixelTranslate,);
			}
		}
	return;
}

async function showImage(src, alt, pixelTranslate) { //show a note
	var myimage = document.createElement('img');
	myimage.src = src;
	myimage.width = 64;
	myimage.height = 128;
	myimage.alt = alt;
	myimage.style.transform = 'translateY(' + pixelTranslate + 'px)';
	document.body.appendChild(myimage); //adds image to <body>
}

var i = 0;
var sentData = '{{ sentSongId }}'; //gets song id from /choose
var songId = sentData[0] + sentData[1];
console.log(songId);
if (sentData.length == 3) {
	var modeId = sentData[2];
} else if (sentData.length == 4) {
	var modeId = sentData[2] + sentData[3];
} else {
	var modeId = 'sentData erroneous length';
	console.log("sentData wrong length! - length = " + sentData.length);
}
console.log(modeId);
Initialise(songId);

//type = "audio/mpeg"

</script>

</head>

<title>Mmmmusic</title>

<style type = "text/css" >
body {
	background-image: url('../static/images/2staff.jpg');
	background-size: 1920px 128px;
	background-color: #E6E6E6;
	font-size: 20px;
	margin: 0;
}

a {
	color: #E6E6E6;
	transition: all 1s;
}

li:hover a {
	color: #141414;
}

ul {
	list-style-type:none;
	padding-left: 0;
}
 
li {
	margin: 20px 0px 20px 0px;
	padding: 10px;
	border-color: #28394D;
	border-width: 4px;
	border-style: solid;
	transition: all 0.8s;
}

li:hover {
	background-color: #32CD32;
	padding: 15px;
}
</style>

<body>
	<input type = "text" id= "metronomeId" Note goes here! </input>
	<input type = "text" id= "noteId" Note goes here! </input>
		<br>
</body>

</html>
